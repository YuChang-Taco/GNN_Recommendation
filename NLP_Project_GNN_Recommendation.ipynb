{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "eb1fa23d",
      "metadata": {
        "id": "eb1fa23d"
      },
      "source": [
        "# Final project: Graph-based recommendation system"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4748fb60",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4748fb60",
        "outputId": "51447237-f327-42ec-97f4-533c4a3e5c44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.1+cu113\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 14.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 16.5 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install required packages.\n",
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b32ad5aa",
      "metadata": {
        "id": "b32ad5aa"
      },
      "outputs": [],
      "source": [
        "# import required modules\n",
        "import argparse\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import Tensor, nn, optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch_geometric.utils import to_undirected\n",
        "from tqdm.auto import tqdm, trange"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6aa45a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6aa45a7",
        "outputId": "1c8a8983-4cbd-4ec7-da5d-d4459670a2cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LightGCN-PyTorch'...\n",
            "remote: Enumerating objects: 534, done.\u001b[K\n",
            "remote: Counting objects: 100% (155/155), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 534 (delta 140), reused 133 (delta 133), pack-reused 379\u001b[K\n",
            "Receiving objects: 100% (534/534), 81.83 MiB | 14.27 MiB/s, done.\n",
            "Resolving deltas: 100% (320/320), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/gusye1234/LightGCN-PyTorch.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3aa2e2ff",
      "metadata": {
        "id": "3aa2e2ff"
      },
      "outputs": [],
      "source": [
        "train_interaction, test_interaction = [], []\n",
        "\n",
        "# load training data\n",
        "with open(\"./LightGCN-PyTorch/data/gowalla/train.txt\",\"r\") as f:\n",
        "    for line in f:\n",
        "        if len(line) > 0:\n",
        "            line = line.strip('\\n').split(' ')\n",
        "            items = [int(i) for i in line[1:]]\n",
        "            uid = [int(line[0])] * len(items)\n",
        "            train_interaction.extend(list(zip(uid,items)))\n",
        "            \n",
        "# load testing data\n",
        "with open(\"./LightGCN-PyTorch/data/gowalla/test.txt\",\"r\") as f:\n",
        "    for line in f:\n",
        "        if len(line) > 0:\n",
        "            line = line.strip('\\n').split(' ')\n",
        "            items = [int(i) for i in line[1:]]\n",
        "            uid = [int(line[0])] * len(items)\n",
        "            test_interaction.extend(list(zip(uid,items)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ef229e6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ef229e6",
        "outputId": "ff49ec7f-c267-41ab-951c-8d80aff49a43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training data: 810128\n",
            "Number of testing data: 217242\n",
            "After filtering, there are 217242 data remains\n"
          ]
        }
      ],
      "source": [
        "# load interaction\n",
        "train_interaction = pd.DataFrame(train_interaction, columns=[\"userId\", \"itemId\"])\n",
        "test_interaction = pd.DataFrame(test_interaction, columns=[\"userId\", \"itemId\"])\n",
        "print(\"Number of training data:\", train_interaction.shape[0])\n",
        "print(\"Number of testing data:\", test_interaction.shape[0])\n",
        "\n",
        "# create user mapping\n",
        "user_mapping = {v: i for i, v in enumerate(\n",
        "    train_interaction[\"userId\"].unique())}\n",
        "item_mapping = {v: i for i, v in enumerate(\n",
        "    train_interaction[\"itemId\"].unique())}\n",
        "\n",
        "# filter unseen testing data\n",
        "condition = (test_interaction[\"userId\"].isin(user_mapping)) & (\n",
        "    test_interaction[\"itemId\"].isin(item_mapping))\n",
        "test_interaction = test_interaction[condition]\n",
        "print(f\"After filtering, there are {test_interaction.shape[0]} data remains\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73c226ea",
      "metadata": {
        "id": "73c226ea"
      },
      "outputs": [],
      "source": [
        "# relabel user & item index\n",
        "train_interaction[\"userId\"] = train_interaction[\"userId\"].apply(\n",
        "    user_mapping.get)\n",
        "train_interaction[\"itemId\"] = train_interaction[\"itemId\"].apply(\n",
        "    item_mapping.get)\n",
        "test_interaction[\"userId\"] = test_interaction[\"userId\"].apply(user_mapping.get)\n",
        "test_interaction[\"itemId\"] = test_interaction[\"itemId\"].apply(item_mapping.get)\n",
        "assert train_interaction.isnull().sum().any() == 0\n",
        "assert test_interaction.isnull().sum().any() == 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f490a33",
      "metadata": {
        "id": "8f490a33"
      },
      "outputs": [],
      "source": [
        "def get_user_positive_items(interactions):\n",
        "    \"\"\"Generates dictionary of positive items for each user\n",
        "\n",
        "    Args:\n",
        "        interactions (torch.Tensor): N by 2 list of interaction\n",
        "\n",
        "    Returns:\n",
        "        dict: dictionary of positive items for each user\n",
        "    \"\"\"\n",
        "    user_pos_items = {}\n",
        "    for i in range(interactions.shape[0]):\n",
        "        user = interactions[i][0].item()\n",
        "        item = interactions[i][1].item()\n",
        "        if user not in user_pos_items:\n",
        "            user_pos_items[user] = []\n",
        "        user_pos_items[user].append(item)\n",
        "    return user_pos_items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa20ffd5",
      "metadata": {
        "id": "aa20ffd5"
      },
      "outputs": [],
      "source": [
        "num_users, num_items = len(user_mapping), len(item_mapping)\n",
        "train_interaction = train_interaction.values\n",
        "test_interaction = test_interaction.values\n",
        "\n",
        "# get interacted item list\n",
        "train_user_record = get_user_positive_items(train_interaction)\n",
        "test_user_record = get_user_positive_items(train_interaction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a316be7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a316be7",
        "outputId": "897dcb7c-d468-4b60-c82e-c61a2611cb8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of users:29858 | Number of items:40981\n"
          ]
        }
      ],
      "source": [
        "train_edge_index = torch.tensor(train_interaction).T\n",
        "test_edge_index = torch.tensor(test_interaction).T\n",
        "\n",
        "train_edge_index[1] = train_edge_index[1] + num_users\n",
        "test_edge_index[1] = test_edge_index[1] + num_users\n",
        "print(f\"Number of users:{num_users} | Number of items:{num_items}\")\n",
        "\n",
        "# transform to undirected\n",
        "train_edge_index = to_undirected(train_edge_index)\n",
        "test_edge_index = to_undirected(test_edge_index)\n",
        "assert train_edge_index.shape[0] == 2\n",
        "assert test_edge_index.shape[0] == 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cf10700",
      "metadata": {
        "id": "5cf10700"
      },
      "source": [
        "## Tools for evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afd9c175",
      "metadata": {
        "id": "afd9c175"
      },
      "outputs": [],
      "source": [
        "def RecallPrecision_ATk(groundTruth, r, k):\n",
        "    \"\"\"Computers recall @ k and precision @ k\n",
        "\n",
        "    Args:\n",
        "        groundTruth (list): list of lists containing highly rated items of each user\n",
        "        r (list): list of lists indicating whether each top k item recommended to each user\n",
        "            is a top k ground truth item or not\n",
        "        k (intg): determines the top k items to compute precision and recall on\n",
        "\n",
        "    Returns:\n",
        "        tuple: recall @ k, precision @ k\n",
        "    \"\"\"\n",
        "    num_correct_pred = torch.sum(\n",
        "        r, dim=-1)  # number of correctly predicted items per user\n",
        "    # number of items liked by each user in the test set\n",
        "    user_num_liked = torch.Tensor([len(groundTruth[i])\n",
        "                                  for i in range(len(groundTruth))])\n",
        "    recall = torch.mean(num_correct_pred / user_num_liked)\n",
        "    precision = torch.mean(num_correct_pred) / k\n",
        "    return recall.item(), precision.item()\n",
        "\n",
        "\n",
        "def NDCGatK_r(groundTruth, r, k):\n",
        "    \"\"\"Computes Normalized Discounted Cumulative Gain (NDCG) @ k\n",
        "\n",
        "    Args:\n",
        "        groundTruth (list): list of lists containing highly rated items of each user\n",
        "        r (list): list of lists indicating whether each top k item recommended to each user\n",
        "            is a top k ground truth item or not\n",
        "        k (int): determines the top k items to compute ndcg on\n",
        "\n",
        "    Returns:\n",
        "        float: ndcg @ k\n",
        "    \"\"\"\n",
        "    assert len(r) == len(groundTruth)\n",
        "\n",
        "    test_matrix = torch.zeros((len(r), k))\n",
        "\n",
        "    for i, items in enumerate(groundTruth):\n",
        "        length = min(len(items), k)\n",
        "        test_matrix[i, :length] = 1\n",
        "    max_r = test_matrix\n",
        "    idcg = torch.sum(max_r * 1. / torch.log2(torch.arange(2, k + 2)), axis=1)\n",
        "    dcg = r * (1. / torch.log2(torch.arange(2, k + 2)))\n",
        "    dcg = torch.sum(dcg, axis=1)\n",
        "    idcg[idcg == 0.] = 1.\n",
        "    ndcg = dcg / idcg\n",
        "    ndcg[torch.isnan(ndcg)] = 0.\n",
        "    return torch.mean(ndcg).item()\n",
        "\n",
        "\n",
        "def get_metrics(predictions, interactions, k):\n",
        "    \"\"\"\n",
        "    Computes the evaluation metrics: recall, precision, and ndcg @ k\n",
        "    Args:\n",
        "        predictions (np.array): a sorted array with size (num_user,k)\n",
        "                                where predictions[i,j] denotes the j-th item user i might like\n",
        "        interactions (list): list of lists indicating whether each top k item recommended to each user\n",
        "            is a top k ground truth item or not\n",
        "        k (int): determines the top k items to compute ndcg on\n",
        "    \"\"\"\n",
        "    top_K_items = torch.tensor(predictions)\n",
        "    interactions = torch.tensor(interactions)\n",
        "\n",
        "    # get all unique users in evaluated split\n",
        "    users = interactions[:, 0].unique()\n",
        "\n",
        "    test_user_pos_items = get_user_positive_items(interactions)\n",
        "\n",
        "    # convert test user pos items dictionary into a list\n",
        "    test_user_pos_items_list = [\n",
        "        test_user_pos_items[user.item()] for user in users]\n",
        "\n",
        "    # determine the correctness of topk predictions\n",
        "    r = []\n",
        "    for user in users:\n",
        "        ground_truth_items = test_user_pos_items[user.item()]\n",
        "        label = list(map(lambda x: x in ground_truth_items, top_K_items[user]))\n",
        "        r.append(label)\n",
        "    r = torch.Tensor(np.array(r).astype('float'))\n",
        "\n",
        "    recall, precision = RecallPrecision_ATk(test_user_pos_items_list, r, k)\n",
        "    ndcg = NDCGatK_r(test_user_pos_items_list, r, k)\n",
        "\n",
        "    return recall, precision, ndcg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6642e40a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6642e40a",
        "outputId": "df67c3cc-8a69-4e7b-af96-222dd799afe2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Popolarity] Recall@10: 0.0001, Precision@10: 0.0001, NDCG@10: 0.0001\n"
          ]
        }
      ],
      "source": [
        "# generate a random prediction\n",
        "K = 10\n",
        "predictions = np.array([list(range(K))] * num_users) # n_user * K \n",
        "recall, precision, ndcg = get_metrics(predictions,test_interaction,K)\n",
        "print(f\"[Popolarity] Recall@{K}: {recall:.4f}, Precision@{K}: {precision:.4f}, NDCG@{K}: {ndcg:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c258ba50",
      "metadata": {
        "id": "c258ba50"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b0a72e9",
      "metadata": {
        "id": "6b0a72e9"
      },
      "outputs": [],
      "source": [
        "class TripletUniformPair(Dataset):\n",
        "    def __init__(self, num_item, user_list, pair):\n",
        "        self.num_item = num_item\n",
        "        self.user_list = user_list\n",
        "        self.pair = pair\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        #idx = np.random.randint(len(self.pair))\n",
        "        u = self.pair[idx][0]\n",
        "        i = self.pair[idx][1]\n",
        "        j = np.random.randint(self.num_item)\n",
        "        while j in self.user_list[u]:\n",
        "            j = np.random.randint(self.num_item)\n",
        "        return u, i, j\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pair)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ee1a658",
      "metadata": {
        "id": "3ee1a658"
      },
      "source": [
        "## Loss function: BPR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f30a8c1f",
      "metadata": {
        "id": "f30a8c1f"
      },
      "outputs": [],
      "source": [
        "def bpr_loss(users_emb_final, pos_items_emb_final, neg_items_emb_final):\n",
        "    \"\"\"Bayesian Personalized Ranking Loss as described in https://arxiv.org/abs/1205.2618\n",
        "\n",
        "    Args:\n",
        "        users_emb_final (torch.Tensor): e_u_k\n",
        "        pos_items_emb_final (torch.Tensor): positive e_i_k\n",
        "        neg_items_emb_final (torch.Tensor): negative e_i_k\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: scalar bpr loss value\n",
        "    \"\"\"\n",
        "\n",
        "    pos_scores = torch.mul(users_emb_final, pos_items_emb_final)\n",
        "    # predicted scores of positive samples\n",
        "    pos_scores = torch.sum(pos_scores, dim=-1)\n",
        "    neg_scores = torch.mul(users_emb_final, neg_items_emb_final)\n",
        "    # predicted scores of negative samples\n",
        "    neg_scores = torch.sum(neg_scores, dim=-1)\n",
        "    loss = -torch.mean(torch.log(10e-8 + torch.sigmoid(pos_scores - neg_scores)))\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4175a90",
      "metadata": {
        "id": "f4175a90"
      },
      "source": [
        "## Problem1: Implementing NGCF\n",
        "\n",
        "### High-order Propagation in NGCF\n",
        "Between each layer, NGCF uses the following propagation rule for user and item embeddings.\n",
        "\n",
        "\\begin{equation}\n",
        "e_u^{(k)} = LeakyReLU \\left(  m^{(k)}_{u \\leftarrow u}  + \\sum_{i\\in N_u}   m^{(k)}_{u \\leftarrow i} \\right)\\\\\n",
        "m^{(k)}_{u \\leftarrow u} = W_1^{(k)}e_u^{(k-1)},\\\\\n",
        "m^{(k)}_{u \\leftarrow i} = \\frac{1}{\\sqrt{|N_u||N_i|}} \\left( W_1^{(k)}e_i^{(k-1)} + W_2^{(k)} \\left( e_i^{(k-1)} \\odot e_u^{(k-1)} \\right)  \\right)\n",
        "\\end{equation}\n",
        "\n",
        "$N_u$: the set of all neighbors of user $u$ (items liked by $u$)\n",
        "\n",
        "$N_i$: the set of all neighbors of item $i$ (users who liked $i$)\n",
        "\n",
        "$e_u^{(k)}$ : k-th layer user embedding\n",
        "\n",
        "$e_i^{(k)}$ : k-th layer item embedding\n",
        "\n",
        "\n",
        "\n",
        "### Layer Combination and Model Prediction\n",
        "We combine the embeddings obtained at each layer of propagation to form the final embeddings for all user and item, $e_u$ and $e_i$ via the follwing equation.\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "e_u = e_u^{(0)} || \\cdots || e_u^{(K)} \\quad e_i = e_i^{(0)} || \\cdots || e_i^{(K)}\n",
        "\\end{equation}\n",
        "\n",
        "$||$ : denotes the concatenate operation\n",
        "\n",
        "The model prediction is obtained by taking the inner product of the final user and item embeddings.\n",
        "\n",
        "\\begin{equation}\n",
        "\\hat{y}_{ui} = e_u^Te_i\n",
        "\\end{equation}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a275a51",
      "metadata": {
        "id": "4a275a51"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import MessagePassing\n",
        "from torch import Tensor\n",
        "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
        "from torch_sparse import SparseTensor, matmul"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f987b0c5",
      "metadata": {
        "id": "f987b0c5"
      },
      "outputs": [],
      "source": [
        "class NGCF(MessagePassing):\n",
        "    def __init__(self, num_users, num_items, embedding_dim=8, n_layers=3, add_self_loops=False):\n",
        "        \"\"\"Initializes NGCF Model\n",
        "\n",
        "        Args:\n",
        "            num_users (int): Number of users\n",
        "            num_items (int): Number of items\n",
        "            embedding_dim (int, optional): Dimensionality of embeddings. Defaults to 8.\n",
        "            K (int, optional): Number of message passing layers. Defaults to 3.\n",
        "            add_self_loops (bool, optional): Whether to add self loops for message passing. Defaults to False.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_users, self.num_items = num_users, num_items\n",
        "        self.embedding_dim, self.n_layers = embedding_dim, n_layers\n",
        "        self.add_self_loops = add_self_loops\n",
        "\n",
        "        self.users_emb = nn.Embedding(\n",
        "            num_embeddings=self.num_users, embedding_dim=self.embedding_dim)  # e_u^0\n",
        "        self.items_emb = nn.Embedding(\n",
        "            num_embeddings=self.num_items, embedding_dim=self.embedding_dim)  # e_i^0\n",
        "        self.W1_list = nn.ModuleList(\n",
        "            [nn.Linear(self.embedding_dim, self.embedding_dim, bias=False) for _ in range(n_layers)])\n",
        "        self.W2_list = nn.ModuleList(\n",
        "            [nn.Linear(self.embedding_dim, self.embedding_dim, bias=False) for _ in range(n_layers)])\n",
        "\n",
        "    def forward(self, edge_index):\n",
        "        \"\"\"Forward propagation of NGCF Model.\n",
        "\n",
        "        Args:\n",
        "            edge_index (SparseTensor): adjacency matrix\n",
        "\n",
        "        Returns:\n",
        "            tuple (Tensor): e_u_k, e_i_k\n",
        "        \"\"\"\n",
        "        edge_index, norm = gcn_norm(\n",
        "            edge_index, add_self_loops=self.add_self_loops)\n",
        "\n",
        "        emb_0 = torch.cat(\n",
        "            [self.users_emb.weight, self.items_emb.weight])\n",
        "        embs = [emb_0]\n",
        "        emb_k = emb_0\n",
        "\n",
        "        # multi-scale diffusion\n",
        "        for i in range(self.n_layers):\n",
        "            emb_k = self.propagate(edge_index, x=emb_k,\n",
        "                                   K=i, norm=norm) + self.W1_list[i](emb_k)\n",
        "            emb_k = F.leaky_relu(emb_k)\n",
        "            embs.append(emb_k)\n",
        "\n",
        "        emb_final = torch.cat(embs, dim=1)\n",
        "\n",
        "        users_emb_final, items_emb_final = torch.split(\n",
        "            emb_final, [self.num_users, self.num_items])\n",
        "\n",
        "        return users_emb_final, items_emb_final\n",
        "\n",
        "    def message(self, x_i: Tensor, x_j: Tensor, K: int, norm: Tensor) -> Tensor:\n",
        "        return norm.view(-1, 1) * (self.W1_list[K](x_j) + self.W2_list[K](x_i * x_j))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acb3b2f0",
      "metadata": {
        "id": "acb3b2f0"
      },
      "outputs": [],
      "source": [
        "def get_predictions(user_embedding, item_embedding, exclude_user_list, k):\n",
        "    \"\"\"Computes the evaluation metrics: recall, precision, and ndcg @ k\n",
        "\n",
        "    Args:\n",
        "        model (LighGCN): lightgcn model\n",
        "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
        "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
        "        k (int): determines the top k items to compute metrics on\n",
        "\n",
        "    Returns:\n",
        "        tuple: recall @ k, precision @ k, ndcg @ k\n",
        "    \"\"\"\n",
        "\n",
        "    # get ratings between every user and item - shape is num users x num movies\n",
        "    rating = torch.matmul(user_embedding.cpu(), item_embedding.cpu().T)\n",
        "\n",
        "    for user_pos_items in exclude_user_list:\n",
        "        # gets all the positive items for each user from the edge index\n",
        "        # get coordinates of all edges to exclude\n",
        "        exclude_users = []\n",
        "        exclude_items = []\n",
        "        for user, items in user_pos_items.items():\n",
        "            exclude_users.extend([user] * len(items))\n",
        "            exclude_items.extend(items)\n",
        "\n",
        "        # set ratings of excluded edges to large negative value\n",
        "        rating[exclude_users, exclude_items] = -10e8\n",
        "\n",
        "    # get the top k recommended items for each user\n",
        "    _, top_K_items = torch.topk(rating, k=k)\n",
        "\n",
        "    return top_K_items.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd9e9e16",
      "metadata": {
        "id": "dd9e9e16"
      },
      "source": [
        "# Training\n",
        "\n",
        "Your test set performance should be in line with the following (*K=20*):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ecc4b6e",
      "metadata": {
        "id": "8ecc4b6e"
      },
      "outputs": [],
      "source": [
        "def l2_reg_loss(reg, *args):\n",
        "    emb_loss = 0\n",
        "    for emb in args:\n",
        "        emb_loss += torch.norm(emb, p=2)\n",
        "    return emb_loss * reg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39b46c72",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39b46c72",
        "outputId": "9504393c-c431-4ae6-a0d0-75758aba2ba2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "train_dataset = TripletUniformPair(\n",
        "    num_item=num_items, user_list=train_user_record, pair=train_interaction)\n",
        "train_loader = DataLoader(train_dataset, batch_size=2048, pin_memory=True,\n",
        "                          num_workers=4, )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18a5137e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18a5137e",
        "outputId": "b6365970-9d26-4e0b-bd64-663b8af4c846"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device cuda.\n"
          ]
        }
      ],
      "source": [
        "# training configs\n",
        "device = \"cuda\"\n",
        "EPOCHS = 10\n",
        "K = 20\n",
        "L2_reg = 1e-6\n",
        "print(f\"Using device {device}.\")\n",
        "\n",
        "model = NGCF(num_users, num_items,embedding_dim=32, n_layers=2)\n",
        "model = model.to(device)\n",
        "model.train()\n",
        "\n",
        "# initialize parameters\n",
        "for p in model.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "train_edge_index = train_edge_index.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef072d84",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232,
          "referenced_widgets": [
            "4ccc0f0be3bb46238554db1afa824bcc",
            "2ea553a16d7f4454988dba6579bc21d7",
            "a0c52d662dce4bd7b804d3e2adb8ec38",
            "b56003c15bc1429e9081b722e30e3c97",
            "fb0997baf8f34c3699664ca2e257d5e3",
            "57878d8114b04aca9baed2dd411d71f2",
            "dd90ee6bd99f4875848d5ff1ebdb0157",
            "34662d800df6422e945840cc20b3f4e4",
            "8e3ce19400c640a7ad3b886851750a32",
            "bc6212bfdff14eaf8dfe57b243942c3d",
            "65782b7134a249dcab284680ee7307d6"
          ]
        },
        "id": "ef072d84",
        "outputId": "4e79bd33-3a16-4b55-c1af-1641bed2da4f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ccc0f0be3bb46238554db1afa824bcc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test_recall@20: 0.0741, Test_precision@20: 0.0251, Test_ndcg@20: 0.0649\n",
            "Test_recall@20: 0.0590, Test_precision@20: 0.0206, Test_ndcg@20: 0.0512\n",
            "Test_recall@20: 0.0705, Test_precision@20: 0.0243, Test_ndcg@20: 0.0619\n",
            "Test_recall@20: 0.0778, Test_precision@20: 0.0264, Test_ndcg@20: 0.0672\n",
            "Test_recall@20: 0.0833, Test_precision@20: 0.0279, Test_ndcg@20: 0.0708\n",
            "Test_recall@20: 0.0866, Test_precision@20: 0.0289, Test_ndcg@20: 0.0718\n",
            "Test_recall@20: 0.0887, Test_precision@20: 0.0295, Test_ndcg@20: 0.0748\n",
            "Test_recall@20: 0.0890, Test_precision@20: 0.0296, Test_ndcg@20: 0.0742\n",
            "Test_recall@20: 0.0914, Test_precision@20: 0.0301, Test_ndcg@20: 0.0751\n",
            "Test_recall@20: 0.0942, Test_precision@20: 0.0310, Test_ndcg@20: 0.0792\n"
          ]
        }
      ],
      "source": [
        "for epoch in trange(EPOCHS):\n",
        "    running_loss = []\n",
        "    for user_indices, pos_item_indices, neg_item_indices in train_loader:\n",
        "        # forward propagation\n",
        "        optimizer.zero_grad()\n",
        "        users_emb_final, items_emb_final = model.forward(train_edge_index)\n",
        "\n",
        "        # mini batching\n",
        "        user_indices, pos_item_indices, neg_item_indices = user_indices.to(\n",
        "            device), pos_item_indices.to(device), neg_item_indices.to(device)\n",
        "        users_emb_final = users_emb_final[user_indices]\n",
        "        pos_items_emb_final = items_emb_final[pos_item_indices]\n",
        "        neg_items_emb_final = items_emb_final[neg_item_indices]\n",
        "\n",
        "        # loss computation\n",
        "        reg_loss = l2_reg_loss(L2_reg, users_emb_final, pos_items_emb_final)\n",
        "        loss = bpr_loss(users_emb_final, pos_items_emb_final,neg_items_emb_final) + reg_loss\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss.append(loss.item())\n",
        "\n",
        "    # evaluation\n",
        "    running_loss = np.mean(running_loss)\n",
        "\n",
        "    if (epoch + 1) % 1 == 0:\n",
        "        users_emb_final, items_emb_final = model.forward(train_edge_index)\n",
        "        predictions = get_predictions(\n",
        "            users_emb_final, items_emb_final, exclude_user_list=[train_user_record], k=K)\n",
        "        recall, precision, ndcg = get_metrics(\n",
        "            predictions, test_interaction, k=K)\n",
        "        print(f\"Test_recall@{K}: {recall:.4f}, Test_precision@{K}: {precision:.4f}, Test_ndcg@{K}: {ndcg:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "968d5223",
      "metadata": {
        "id": "968d5223"
      },
      "source": [
        "## Problem2: Implementing LightGCN\n",
        "\n",
        "### Light Graph Convolution\n",
        "Between each layer, LightGCN uses the following propagation rule for user and item embeddings.\n",
        "\n",
        "\\begin{equation}\n",
        "e_u^{(k+1)} = \\sum_{i \\in N_u} \\frac{1}{\\sqrt{|N_u|}\\sqrt{|N_i|}} e_i^{(k)} \\quad e_i^{(k+1)} = \\sum_{u \\in N_i} \\frac{1}{\\sqrt{|N_i|}\\sqrt{|N_u|}} e_u^{(k)}\n",
        "\\end{equation}\n",
        "\n",
        "$N_u$: the set of all neighbors of user $u$ (items liked by $u$)\n",
        "\n",
        "$N_i$: the set of all neighbors of item $i$ (users who liked $i$)\n",
        "\n",
        "$e_u^{(k)}$ : k-th layer user embedding\n",
        "\n",
        "$e_i^{(k)}$ : k-th layer item embedding\n",
        "\n",
        "\n",
        "\n",
        "### Layer Combination and Model Prediction\n",
        "The only trainable parameters of LightGCN are the 0-th layer embeddings $e_u^{(0)}$ and $e_i^{(0)}$ for each user and item. We combine the embeddings obtained at each layer of propagation to form the final embeddings for all user and item, $e_u$ and $e_i$ via the follwing equation.\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "e_u = \\sum_{k = 0}^K \\alpha_k e_u^{(k)} \\quad e_i = \\sum_{k = 0}^K \\alpha_k e_i^{(k)}\n",
        "\\end{equation}\n",
        "\n",
        "$\\alpha_k$ : hyperparameter which weights the contribution of the k-th layer embedding to the final embedding\n",
        "\n",
        "The model prediction is obtained by taking the inner product of the final user and item embeddings.\n",
        "\n",
        "\\begin{equation}\n",
        "\\hat{y}_{ui} = e_u^Te_i\n",
        "\\end{equation}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ef0ea64",
      "metadata": {
        "id": "4ef0ea64"
      },
      "outputs": [],
      "source": [
        "class LightGCN(MessagePassing):\n",
        "    \"\"\"LightGCN Model as proposed in https://arxiv.org/abs/2002.02126\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_users, num_items, embedding_dim, n_layers, add_self_loops=False):\n",
        "        \"\"\"Initializes LightGCN Model\n",
        "\n",
        "        Args:\n",
        "            num_users (int): Number of users\n",
        "            num_items (int): Number of items\n",
        "            embedding_dim (int, optional): Dimensionality of embeddings. Defaults to 8.\n",
        "            K (int, optional): Number of message passing layers. Defaults to 3.\n",
        "            add_self_loops (bool, optional): Whether to add self loops for message passing. Defaults to False.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_users, self.num_items = num_users, num_items\n",
        "        self.embedding_dim, self.n_layers = embedding_dim, n_layers\n",
        "        self.add_self_loops = add_self_loops\n",
        "\n",
        "        self.users_emb = nn.Embedding(\n",
        "            num_embeddings=self.num_users, embedding_dim=self.embedding_dim)  # e_u^0\n",
        "        self.items_emb = nn.Embedding(\n",
        "            num_embeddings=self.num_items, embedding_dim=self.embedding_dim)  # e_i^0\n",
        "\n",
        "    def forward(self, edge_index: Tensor):\n",
        "        edge_index, norm = gcn_norm(edge_index, add_self_loops=self.add_self_loops)\n",
        "\n",
        "        emb_0 = torch.cat(\n",
        "            [self.users_emb.weight, self.items_emb.weight])  # E^0\n",
        "        embs = [emb_0]\n",
        "        emb_k = emb_0\n",
        "\n",
        "        # multi-scale diffusion\n",
        "        for i in range(self.n_layers):\n",
        "            emb_k = self.propagate(edge_index, x=emb_k,norm=norm)\n",
        "            \n",
        "            embs.append(emb_k)\n",
        "\n",
        "        embs = torch.stack(embs, dim=1)\n",
        "        emb_final = torch.mean(embs, dim=1)  # E^K\n",
        "\n",
        "        users_emb_final, items_emb_final = torch.split(\n",
        "            emb_final, [self.num_users, self.num_items])  # splits into e_u^K and e_i^K\n",
        "        return users_emb_final, items_emb_final\n",
        "\n",
        "    def message(self, x_j: Tensor, norm: Tensor) -> Tensor:\n",
        "\n",
        "        return norm.view(-1,1) * x_j"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ecb05d5",
      "metadata": {
        "id": "2ecb05d5"
      },
      "source": [
        "## Training!\n",
        "Let's see if your LightGCN outperforms NGCF!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efa6693e",
      "metadata": {
        "scrolled": true,
        "id": "efa6693e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb30c810-42a9-4926-dd4b-500d5fdb7644"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device cuda.\n"
          ]
        }
      ],
      "source": [
        "# training configs\n",
        "device = \"cuda\"\n",
        "EPOCHS = 30\n",
        "K = 20\n",
        "L2_reg = 1e-6\n",
        "print(f\"Using device {device}.\")\n",
        "\n",
        "model = LightGCN(num_users, num_items,embedding_dim=32, n_layers=2)\n",
        "model = model.to(device)\n",
        "model.train()\n",
        "\n",
        "# initialize parameters\n",
        "for p in model.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "train_edge_index = train_edge_index.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b9ddff6",
      "metadata": {
        "id": "5b9ddff6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597,
          "referenced_widgets": [
            "f1ffe5343f1f425e8180ece66df1bfee",
            "7f6fa155eda14fe28921b5a3f009da71",
            "7622efa431eb48c1a10fc8f882c23732",
            "029c48bc433641618250f21e49f2051e",
            "ccfd2f7fdd0d4f2aaa50ef7d326813e7",
            "8e6c4373ee0c4eadb8bfb2bd6d6aa1b1",
            "b1e9116591664348aeec7edf4cea1a0d",
            "c70e6f624dff4afa9bdb18499145bc4e",
            "749aade3bad144b3b00f41f50f4e59b4",
            "650215d6ec724cf4bfd141957d1e6d03",
            "7191c50b64a943deb3a2c2ae35f160c2"
          ]
        },
        "outputId": "377bea5c-a7ea-44a4-a07a-da5b88472a53"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1ffe5343f1f425e8180ece66df1bfee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test_recall@20: 0.0668, Test_precision@20: 0.0227, Test_ndcg@20: 0.0576\n",
            "Test_recall@20: 0.0709, Test_precision@20: 0.0240, Test_ndcg@20: 0.0611\n",
            "Test_recall@20: 0.0739, Test_precision@20: 0.0248, Test_ndcg@20: 0.0640\n",
            "Test_recall@20: 0.0769, Test_precision@20: 0.0257, Test_ndcg@20: 0.0667\n",
            "Test_recall@20: 0.0800, Test_precision@20: 0.0266, Test_ndcg@20: 0.0694\n",
            "Test_recall@20: 0.0820, Test_precision@20: 0.0272, Test_ndcg@20: 0.0712\n",
            "Test_recall@20: 0.0847, Test_precision@20: 0.0280, Test_ndcg@20: 0.0734\n",
            "Test_recall@20: 0.0862, Test_precision@20: 0.0284, Test_ndcg@20: 0.0752\n",
            "Test_recall@20: 0.0875, Test_precision@20: 0.0288, Test_ndcg@20: 0.0765\n",
            "Test_recall@20: 0.0891, Test_precision@20: 0.0292, Test_ndcg@20: 0.0778\n",
            "Test_recall@20: 0.0902, Test_precision@20: 0.0295, Test_ndcg@20: 0.0789\n",
            "Test_recall@20: 0.0915, Test_precision@20: 0.0299, Test_ndcg@20: 0.0800\n",
            "Test_recall@20: 0.0927, Test_precision@20: 0.0303, Test_ndcg@20: 0.0811\n",
            "Test_recall@20: 0.0938, Test_precision@20: 0.0306, Test_ndcg@20: 0.0819\n",
            "Test_recall@20: 0.0951, Test_precision@20: 0.0309, Test_ndcg@20: 0.0829\n",
            "Test_recall@20: 0.0962, Test_precision@20: 0.0313, Test_ndcg@20: 0.0841\n",
            "Test_recall@20: 0.0974, Test_precision@20: 0.0317, Test_ndcg@20: 0.0853\n",
            "Test_recall@20: 0.0991, Test_precision@20: 0.0321, Test_ndcg@20: 0.0866\n",
            "Test_recall@20: 0.1008, Test_precision@20: 0.0326, Test_ndcg@20: 0.0878\n",
            "Test_recall@20: 0.1023, Test_precision@20: 0.0331, Test_ndcg@20: 0.0891\n",
            "Test_recall@20: 0.1036, Test_precision@20: 0.0334, Test_ndcg@20: 0.0902\n",
            "Test_recall@20: 0.1050, Test_precision@20: 0.0339, Test_ndcg@20: 0.0914\n",
            "Test_recall@20: 0.1065, Test_precision@20: 0.0343, Test_ndcg@20: 0.0926\n",
            "Test_recall@20: 0.1082, Test_precision@20: 0.0348, Test_ndcg@20: 0.0939\n",
            "Test_recall@20: 0.1096, Test_precision@20: 0.0352, Test_ndcg@20: 0.0951\n",
            "Test_recall@20: 0.1110, Test_precision@20: 0.0356, Test_ndcg@20: 0.0963\n",
            "Test_recall@20: 0.1123, Test_precision@20: 0.0360, Test_ndcg@20: 0.0973\n",
            "Test_recall@20: 0.1138, Test_precision@20: 0.0364, Test_ndcg@20: 0.0984\n",
            "Test_recall@20: 0.1151, Test_precision@20: 0.0368, Test_ndcg@20: 0.0995\n",
            "Test_recall@20: 0.1160, Test_precision@20: 0.0371, Test_ndcg@20: 0.1003\n"
          ]
        }
      ],
      "source": [
        "for epoch in trange(EPOCHS):\n",
        "    running_loss = []\n",
        "    for user_indices, pos_item_indices, neg_item_indices in train_loader:\n",
        "        # forward propagation\n",
        "        optimizer.zero_grad()\n",
        "        users_emb_final, items_emb_final = model.forward(train_edge_index)\n",
        "\n",
        "        # mini batching\n",
        "        user_indices, pos_item_indices, neg_item_indices = user_indices.to(\n",
        "            device), pos_item_indices.to(device), neg_item_indices.to(device)\n",
        "        users_emb_final = users_emb_final[user_indices]\n",
        "        pos_items_emb_final = items_emb_final[pos_item_indices]\n",
        "        neg_items_emb_final = items_emb_final[neg_item_indices]\n",
        "\n",
        "        # loss computation\n",
        "        reg_loss  = l2_reg_loss(L2_reg, users_emb_final, pos_items_emb_final)\n",
        "        loss = bpr_loss(users_emb_final, pos_items_emb_final,neg_items_emb_final) + reg_loss\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss.append(loss.item())\n",
        "\n",
        "    # evaluation\n",
        "    running_loss = np.mean(running_loss)\n",
        "\n",
        "    if (epoch + 1) % 1 == 0:\n",
        "        users_emb_final, items_emb_final = model.forward(train_edge_index)\n",
        "        predictions = get_predictions(\n",
        "            users_emb_final, items_emb_final, exclude_user_list=[train_user_record], k=K)\n",
        "        recall, precision, ndcg = get_metrics(\n",
        "            predictions, test_interaction, k=K)\n",
        "        print(f\"Test_recall@{K}: {recall:.4f}, Test_precision@{K}: {precision:.4f}, Test_ndcg@{K}: {ndcg:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def InfoNCE(view1, view2, temperature):\n",
        "    view1, view2 = F.normalize(view1, dim=1), F.normalize(view2, dim=1)\n",
        "    pos_score = (view1 * view2).sum(dim=-1)\n",
        "    pos_score = torch.exp(pos_score / temperature)\n",
        "    ttl_score = torch.matmul(view1, view2.transpose(0, 1))\n",
        "    ttl_score = torch.exp(ttl_score / temperature).sum(dim=1)\n",
        "    cl_loss = -torch.log(pos_score / ttl_score)\n",
        "    \n",
        "    return torch.mean(cl_loss)\n",
        "\n",
        "class SimGCL(MessagePassing):\n",
        "    def __init__(self, num_users, num_items, embedding_dim, n_layers, add_self_loops=False, eps=0.2):\n",
        "        \"\"\"Initializes SimGCL Model\n",
        "\n",
        "        Args:\n",
        "            num_users (int): Number of users\n",
        "            num_items (int): Number of items\n",
        "            embedding_dim (int, optional): Dimensionality of embeddings. Defaults to 8.\n",
        "            K (int, optional): Number of message passing layers. Defaults to 3.\n",
        "            add_self_loops (bool, optional): Whether to add self loops for message passing. Defaults to False.\n",
        "            eps: parameter of perterbation\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_users, self.num_items = num_users, num_items\n",
        "        self.embedding_dim, self.n_layers = embedding_dim, n_layers\n",
        "        self.add_self_loops = add_self_loops\n",
        "        self.eps = eps\n",
        "\n",
        "        self.users_emb = nn.Embedding(\n",
        "            num_embeddings=self.num_users, embedding_dim=self.embedding_dim)  # e_u^0\n",
        "        self.items_emb = nn.Embedding(\n",
        "            num_embeddings=self.num_items, embedding_dim=self.embedding_dim)  # e_i^0\n",
        "\n",
        "    def forward(self, edge_index: Tensor, perturbed=False):\n",
        "        edge_index, norm = gcn_norm(edge_index, add_self_loops=self.add_self_loops)\n",
        "\n",
        "        emb_0 = torch.cat(\n",
        "            [self.users_emb.weight, self.items_emb.weight])  # E^0\n",
        "        embs = []\n",
        "        emb_k = emb_0\n",
        "\n",
        "        # multi-scale diffusion\n",
        "        for i in range(self.n_layers):\n",
        "            emb_k = self.propagate(edge_index, x=emb_k,norm=norm)\n",
        "            if perturbed:\n",
        "                random_noise = torch.rand_like(emb_k).to(emb_k.device)\n",
        "                emb_k += torch.sign(emb_k) * F.normalize(random_noise, dim=-1) * self.eps\n",
        "            embs.append(emb_k)\n",
        "\n",
        "        embs = torch.stack(embs, dim=1)\n",
        "        emb_final = torch.mean(embs, dim=1)  # E^K\n",
        "\n",
        "        users_emb_final, items_emb_final = torch.split(\n",
        "            emb_final, [self.num_users, self.num_items])  # splits into e_u^K and e_i^K\n",
        "        return users_emb_final, items_emb_final\n",
        "\n",
        "    def message(self, x_j: Tensor, norm: Tensor) -> Tensor:\n",
        "\n",
        "        return norm.view(-1,1) * x_j\n",
        "    \n",
        "    def cal_cl_loss(self, raw_sparse_edges, idx):\n",
        "        # idx: user-item pair\n",
        "        # [[uid1,uid2,uid3...],[iid1,iid2,....]]\n",
        "        device = idx[0].device\n",
        "        u_idx = torch.unique(idx[0]).to(device) #[3,4,5,4] -> [3,4,5]\n",
        "        i_idx = torch.unique(idx[1]).to(device)\n",
        "        user_view_1, item_view_1 = self.forward(raw_sparse_edges,perturbed=True)\n",
        "        user_view_2, item_view_2 = self.forward(raw_sparse_edges,perturbed=True)\n",
        "        user_cl_loss = InfoNCE(user_view_1[u_idx], user_view_2[u_idx], 0.2)\n",
        "        item_cl_loss = InfoNCE(item_view_1[i_idx], item_view_2[i_idx], 0.2)\n",
        "        return user_cl_loss + item_cl_loss"
      ],
      "metadata": {
        "id": "8W_D16EliIQJ"
      },
      "id": "8W_D16EliIQJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training configs\n",
        "device = \"cuda\"\n",
        "EPOCHS = 30\n",
        "K = 20\n",
        "lmbda = 0.2\n",
        "L2_reg = 1e-4\n",
        "print(f\"Using device {device}.\")\n",
        "\n",
        "model = SimGCL(num_users, num_items,embedding_dim=64, n_layers=2)\n",
        "model = model.to(device)\n",
        "model.train()\n",
        "\n",
        "# initialize parameters\n",
        "for p in model.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "train_edge_index = train_edge_index.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pq6PeheOQ6ek",
        "outputId": "d3cd21b3-774e-42a1-bec9-d6762d8b0826"
      },
      "id": "pq6PeheOQ6ek",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device cuda.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in trange(EPOCHS):\n",
        "    running_loss = []\n",
        "    for user_indices, pos_item_indices, neg_item_indices in train_loader:\n",
        "        # forward propagation\n",
        "        optimizer.zero_grad()\n",
        "        user_embeddings, item_embeddings = model(train_edge_index,False)\n",
        "\n",
        "        # mini batching\n",
        "        user_indices, pos_item_indices, neg_item_indices = user_indices.to(\n",
        "            device), pos_item_indices.to(device), neg_item_indices.to(device)\n",
        "        users_emb_final = user_embeddings[user_indices]\n",
        "        pos_items_emb_final = item_embeddings[pos_item_indices]\n",
        "        neg_items_emb_final = item_embeddings[neg_item_indices]\n",
        "\n",
        "        # loss computation\n",
        "        train_bpr_loss = bpr_loss(users_emb_final, pos_items_emb_final,\n",
        "                                  neg_items_emb_final)\n",
        "\n",
        "        infonce_loss = lmbda * model.cal_cl_loss(train_edge_index, [user_indices,pos_item_indices])\n",
        "        reg_loss  = l2_reg_loss(L2_reg, users_emb_final, pos_items_emb_final)\n",
        "        loss = train_bpr_loss + infonce_loss + reg_loss\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss.append(loss.item())\n",
        "\n",
        "    # evaluation\n",
        "    running_loss = np.mean(running_loss)\n",
        "\n",
        "    if (epoch + 1) % 1 == 0:\n",
        "        users_emb_final, items_emb_final = model(train_edge_index)\n",
        "        predictions = get_predictions(\n",
        "            users_emb_final, items_emb_final, exclude_user_list=[train_user_record], k=K)\n",
        "        recall, precision, ndcg = get_metrics(\n",
        "            predictions, test_interaction, k=K)\n",
        "        print(f\"Test_recall@{K}: {recall:.4f}, Test_precision@{K}: {precision:.4f}, Test_ndcg@{K}: {ndcg:.4f}\")\n"
      ],
      "metadata": {
        "id": "xEJK4JRAm5Vj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597,
          "referenced_widgets": [
            "ac8fa539373a42c3a5eb128ed1b07d34",
            "2ab1f7f2db79493291584ef716d67bec",
            "f470892410d04eb895815e242baa82ff",
            "aebbbc93d56643d48cac587441c4c700",
            "4405f8b5d0f34cb9a57f065f67623867",
            "4841f7fd26574a1da8978a676258aa28",
            "74a7e8f1e00148609d7d9838da33e207",
            "a90556c2201a4a038b89c047f1374119",
            "20cc43ca94184f46bd6a00daf4a9406b",
            "12cc5859e5ae46deaf4207712826cb9e",
            "056cac3f8f02450b8017105de9461510"
          ]
        },
        "outputId": "977d0956-b733-4229-a775-59a6b09fd4b0"
      },
      "id": "xEJK4JRAm5Vj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac8fa539373a42c3a5eb128ed1b07d34"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test_recall@20: 0.1509, Test_precision@20: 0.0460, Test_ndcg@20: 0.1258\n",
            "Test_recall@20: 0.1392, Test_precision@20: 0.0416, Test_ndcg@20: 0.1156\n",
            "Test_recall@20: 0.1254, Test_precision@20: 0.0370, Test_ndcg@20: 0.1041\n",
            "Test_recall@20: 0.1234, Test_precision@20: 0.0366, Test_ndcg@20: 0.1033\n",
            "Test_recall@20: 0.1317, Test_precision@20: 0.0396, Test_ndcg@20: 0.1111\n",
            "Test_recall@20: 0.1423, Test_precision@20: 0.0436, Test_ndcg@20: 0.1201\n",
            "Test_recall@20: 0.1526, Test_precision@20: 0.0474, Test_ndcg@20: 0.1295\n",
            "Test_recall@20: 0.1600, Test_precision@20: 0.0500, Test_ndcg@20: 0.1364\n",
            "Test_recall@20: 0.1638, Test_precision@20: 0.0515, Test_ndcg@20: 0.1406\n",
            "Test_recall@20: 0.1667, Test_precision@20: 0.0524, Test_ndcg@20: 0.1433\n",
            "Test_recall@20: 0.1688, Test_precision@20: 0.0530, Test_ndcg@20: 0.1450\n",
            "Test_recall@20: 0.1706, Test_precision@20: 0.0536, Test_ndcg@20: 0.1464\n",
            "Test_recall@20: 0.1719, Test_precision@20: 0.0540, Test_ndcg@20: 0.1475\n",
            "Test_recall@20: 0.1734, Test_precision@20: 0.0545, Test_ndcg@20: 0.1487\n",
            "Test_recall@20: 0.1744, Test_precision@20: 0.0548, Test_ndcg@20: 0.1496\n",
            "Test_recall@20: 0.1755, Test_precision@20: 0.0551, Test_ndcg@20: 0.1504\n",
            "Test_recall@20: 0.1767, Test_precision@20: 0.0555, Test_ndcg@20: 0.1511\n",
            "Test_recall@20: 0.1768, Test_precision@20: 0.0556, Test_ndcg@20: 0.1514\n",
            "Test_recall@20: 0.1771, Test_precision@20: 0.0557, Test_ndcg@20: 0.1516\n",
            "Test_recall@20: 0.1775, Test_precision@20: 0.0558, Test_ndcg@20: 0.1519\n",
            "Test_recall@20: 0.1774, Test_precision@20: 0.0558, Test_ndcg@20: 0.1519\n",
            "Test_recall@20: 0.1775, Test_precision@20: 0.0559, Test_ndcg@20: 0.1521\n",
            "Test_recall@20: 0.1777, Test_precision@20: 0.0559, Test_ndcg@20: 0.1521\n",
            "Test_recall@20: 0.1776, Test_precision@20: 0.0559, Test_ndcg@20: 0.1521\n",
            "Test_recall@20: 0.1774, Test_precision@20: 0.0559, Test_ndcg@20: 0.1518\n",
            "Test_recall@20: 0.1776, Test_precision@20: 0.0559, Test_ndcg@20: 0.1518\n",
            "Test_recall@20: 0.1775, Test_precision@20: 0.0559, Test_ndcg@20: 0.1517\n",
            "Test_recall@20: 0.1774, Test_precision@20: 0.0558, Test_ndcg@20: 0.1516\n",
            "Test_recall@20: 0.1769, Test_precision@20: 0.0557, Test_ndcg@20: 0.1512\n",
            "Test_recall@20: 0.1765, Test_precision@20: 0.0556, Test_ndcg@20: 0.1509\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4ccc0f0be3bb46238554db1afa824bcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ea553a16d7f4454988dba6579bc21d7",
              "IPY_MODEL_a0c52d662dce4bd7b804d3e2adb8ec38",
              "IPY_MODEL_b56003c15bc1429e9081b722e30e3c97"
            ],
            "layout": "IPY_MODEL_fb0997baf8f34c3699664ca2e257d5e3"
          }
        },
        "2ea553a16d7f4454988dba6579bc21d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57878d8114b04aca9baed2dd411d71f2",
            "placeholder": "​",
            "style": "IPY_MODEL_dd90ee6bd99f4875848d5ff1ebdb0157",
            "value": "100%"
          }
        },
        "a0c52d662dce4bd7b804d3e2adb8ec38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34662d800df6422e945840cc20b3f4e4",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8e3ce19400c640a7ad3b886851750a32",
            "value": 10
          }
        },
        "b56003c15bc1429e9081b722e30e3c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc6212bfdff14eaf8dfe57b243942c3d",
            "placeholder": "​",
            "style": "IPY_MODEL_65782b7134a249dcab284680ee7307d6",
            "value": " 10/10 [06:40&lt;00:00, 39.21s/it]"
          }
        },
        "fb0997baf8f34c3699664ca2e257d5e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57878d8114b04aca9baed2dd411d71f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd90ee6bd99f4875848d5ff1ebdb0157": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34662d800df6422e945840cc20b3f4e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e3ce19400c640a7ad3b886851750a32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc6212bfdff14eaf8dfe57b243942c3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65782b7134a249dcab284680ee7307d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1ffe5343f1f425e8180ece66df1bfee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f6fa155eda14fe28921b5a3f009da71",
              "IPY_MODEL_7622efa431eb48c1a10fc8f882c23732",
              "IPY_MODEL_029c48bc433641618250f21e49f2051e"
            ],
            "layout": "IPY_MODEL_ccfd2f7fdd0d4f2aaa50ef7d326813e7"
          }
        },
        "7f6fa155eda14fe28921b5a3f009da71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e6c4373ee0c4eadb8bfb2bd6d6aa1b1",
            "placeholder": "​",
            "style": "IPY_MODEL_b1e9116591664348aeec7edf4cea1a0d",
            "value": "100%"
          }
        },
        "7622efa431eb48c1a10fc8f882c23732": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c70e6f624dff4afa9bdb18499145bc4e",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_749aade3bad144b3b00f41f50f4e59b4",
            "value": 30
          }
        },
        "029c48bc433641618250f21e49f2051e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_650215d6ec724cf4bfd141957d1e6d03",
            "placeholder": "​",
            "style": "IPY_MODEL_7191c50b64a943deb3a2c2ae35f160c2",
            "value": " 30/30 [15:51&lt;00:00, 32.63s/it]"
          }
        },
        "ccfd2f7fdd0d4f2aaa50ef7d326813e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e6c4373ee0c4eadb8bfb2bd6d6aa1b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1e9116591664348aeec7edf4cea1a0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c70e6f624dff4afa9bdb18499145bc4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "749aade3bad144b3b00f41f50f4e59b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "650215d6ec724cf4bfd141957d1e6d03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7191c50b64a943deb3a2c2ae35f160c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac8fa539373a42c3a5eb128ed1b07d34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ab1f7f2db79493291584ef716d67bec",
              "IPY_MODEL_f470892410d04eb895815e242baa82ff",
              "IPY_MODEL_aebbbc93d56643d48cac587441c4c700"
            ],
            "layout": "IPY_MODEL_4405f8b5d0f34cb9a57f065f67623867"
          }
        },
        "2ab1f7f2db79493291584ef716d67bec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4841f7fd26574a1da8978a676258aa28",
            "placeholder": "​",
            "style": "IPY_MODEL_74a7e8f1e00148609d7d9838da33e207",
            "value": "100%"
          }
        },
        "f470892410d04eb895815e242baa82ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a90556c2201a4a038b89c047f1374119",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20cc43ca94184f46bd6a00daf4a9406b",
            "value": 30
          }
        },
        "aebbbc93d56643d48cac587441c4c700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12cc5859e5ae46deaf4207712826cb9e",
            "placeholder": "​",
            "style": "IPY_MODEL_056cac3f8f02450b8017105de9461510",
            "value": " 30/30 [23:11&lt;00:00, 46.45s/it]"
          }
        },
        "4405f8b5d0f34cb9a57f065f67623867": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4841f7fd26574a1da8978a676258aa28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74a7e8f1e00148609d7d9838da33e207": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a90556c2201a4a038b89c047f1374119": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20cc43ca94184f46bd6a00daf4a9406b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12cc5859e5ae46deaf4207712826cb9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "056cac3f8f02450b8017105de9461510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}